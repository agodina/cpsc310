import csv
from math import log


def read_csv(filename):
    the_file = open(filename, 'r')  # opens the file
    the_reader = csv.reader(the_file, dialect='excel')
    table = []  # makes an empty table
    for row in the_reader:
        if len(row) > 0:
            table.append(row)  # adds each row to the table
    the_file.close()  # closes the file
    return table  # returns the new table


def get_column(table, index):
    column = []  # creates a new table
    for row in table:
        column.append(row[index])
    return column


def partition_instances(instances, att_index, att_domain):
    temp = [[],[]]

    for row in instances:
        if row[att_index] == att_domain:
            temp[0].append(row)
        else:
            temp[1].append(row)
    return temp


def attribute_frequencies(instances, att_index, class_index):
    # get unique list of attribute and class values
    att_vals = list(set(get_column(instances, att_index)))
    class_vals = list(set(get_column(instances, class_index)))
    # initialize the result
    result = {v: [{c: 0 for c in class_vals}, 0] for v in att_vals}  # build up the frequencies
    for row in instances:
        label = row[class_index]
        att_val = row[att_index]
        result[att_val][0][label] += 1
        result[att_val][1] += 1
    return result


def calc_estart(instances, att_index):
    size = len(instances)
    Yes = 0.0
    No = 0.0

    for row in instances:
        if row[att_index] == 'yes':
            Yes += 1
        else:
            No += 1

    p,q = Yes/size, No/size
    e_start = -(p * log(p, 2)) - (q * log(q,2))

    return e_start


def calc_enew(instances, att_index, class_index):
    # get the length of the partition
    D = len(instances)
    # calculate the partition stats for att_index (see below)
    freqs = attribute_frequencies(instances, att_index, class_index)
    # find E_new from freqs (calc weighted avg)
    E_new = 0
    for att_val in freqs:
        D_j = float(freqs[att_val][1])
        probs = [(c / D_j) for (_, c) in freqs[att_val][0].items()]
        E_D_j = -sum([p * log(p, 2) for p in probs])
        E_new += (D_j / D) * E_D_j
    return E_new

def get_best_index(table, indexes):
    e_news = []
    for att in indexes:
        e_start = calc_estart(table, 3)
        e_new = calc_enew(table, att, 3)
        e_news.append(e_start - e_new)
    print(e_news.index((max(e_news))))
    return e_news.index((max(e_news)))


'''def info_gain(instances, att_index, class_index):
    e_start = calc_estart(instances, att_index)'''


def main():
    tableMaster = read_csv('titanic.txt')
    atts = [0, 1, 2]
    best = get_best_index(tableMaster, atts)
    atts.remove(best)
    grouped = group_by(tableMaster, best)
    for item in grouped:
        print(item)
    for partion in grouped:
        best = get_best_index(tableMaster, [0, 1])
        groups = group_by(partion, best)
        for item in groups:
            print(item)



if __name__ == '__main__':
    main()
