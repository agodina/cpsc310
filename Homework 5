import csv
from math import log


def read_csv(filename):
    the_file = open(filename, 'r')  # opens the file
    the_reader = csv.reader(the_file, dialect='excel')
    table = []  # makes an empty table
    for row in the_reader:
        if len(row) > 0:
            table.append(row)  # adds each row to the table
    the_file.close()  # closes the file
    return table  # returns the new table


def get_column(table, index):
    column = []  # creates a new table
    for row in table:
        column.append(row[index])
    return column


def partition_instances(instances, att_index, att_domain):
    temp = [[],[]]

    for row in instances:
        if row[att_index] == att_domain:
            temp[0].append(row)
        else:
            temp[1].append(row)
    return temp


def attribute_frequencies(instances, att_index, class_index):
    # get unique list of attribute and class values
    att_vals = list(set(get_column(instances, att_index)))
    class_vals = list(set(get_column(instances, class_index)))
    # initialize the result
    result = {v: [{c: 0 for c in class_vals}, 0] for v in att_vals}  # build up the frequencies
    for row in instances:
        label = row[class_index]
        att_val = row[att_index]
        result[att_val][0][label] += 1
        result[att_val][1] += 1
    return result


def calc_estart(instances, att_index):
    size = len(instances)
    Yes = 0.0
    No = 0.0

    for row in instances:
        if row[att_index] == 'yes':
            Yes += 1
        else:
            No += 1

    p,q = Yes/size, No/size
    e_start = -(p * log(p, 2)) - (q * log(q,2))

    return e_start


def calc_enew(instances, att_index, class_index):
    # get the length of the partition
    D = len(instances)
    # calculate the partition stats for att_index (see below)
    freqs = attribute_frequencies(instances, att_index, class_index)
    # find E_new from freqs (calc weighted avg)
    E_new = 0
    for att_val in freqs:
        D_j = float(freqs[att_val][1])
        probs = []
        for (_, c) in freqs[att_val][0].items():
            if c != 0:
                probs.append(c / D_j)
        #probs = [(c / D_j) for (_, c) in freqs[att_val][0].items()]
        E_D_j = -sum([p * log(p, 2) for p in probs])
        E_new += (D_j / D) * E_D_j
    return E_new
    
def group_by(table, atts, att_index):
    # create unique list of grouping values
    grouping_values = list(set(get_column(table, att_index)))
    # create list of n empty partitions
    result = []
    for val in grouping_values:
        result.append([])
    # add rows to each partition
    for row in table:
        result[grouping_values.index(row[att_index])].append(row[:])
        
    return result

def get_best_index(table, indexes):
    e_news = []
    for att in indexes:
        e_start = calc_estart(table, 3)
        e_new = calc_enew(table, att, 3)
        e_news.append(e_start - e_new)
    print(indexes[e_news.index(max(e_news))])
    return indexes[e_news.index(max(e_news))]


'''def info_gain(instances, att_index, class_index):
    e_start = calc_estart(instances, att_index)'''

def split_tables(table, atts, final):
    if len(atts) < 1:
        return
    this_atts = atts[:]
    best = get_best_index(table, this_atts)
    this_atts.remove(best)
    grouped = group_by(table, best)
    for item in grouped:
        if len(atts) == 1: #this checks if it will be a leaf
            final.append(item)
    for item in grouped:
        split_tables(item, this_atts, final)
    return final

def main():
    tableMaster = read_csv('titanic.txt')
    atts = [0, 1, 2]
    final = []
    final = split_tables(tableMaster, atts, final)
    for row in final:
        print(row)

if __name__ == '__main__':
    main()
